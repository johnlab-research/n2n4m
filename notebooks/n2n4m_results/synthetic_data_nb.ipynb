{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook showing the performance of N2N4M on an unseen testing set of data with synthetic noise added.\n",
    "CoTCAT [1] is used as a benchmark for performance comparison.  \n",
    "\n",
    "1. Bultel B, Quantin C, Lozac’h L. Description of CoTCAT (Complement to CRISM Analysis Toolkit). IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing. 2015 Jun;8(6):3039–49. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Internal imports\n",
    "import n2n4m.preprocessing as preprocessing\n",
    "from n2n4m.wavelengths import PLEBANI_WAVELENGTHS\n",
    "from n2n4m.model import Noise2Noise1D\n",
    "from n2n4m.model_functions import predict\n",
    "from n2n4m.cotcat_denoise import cotcat_denoise\n",
    "from n2n4m.n2n4m_denoise import instantiate_default_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PACKAGE_DIR = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "DATA_DIR = os.path.join(PACKAGE_DIR, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1000  # If you have memory issues, reduce this number\n",
    "NUM_BLAND_PIXELS = 150_000  # How many bland pixels to add to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False  # uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms.\n",
    "    torch.backends.cudnn.enabled = False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "set_seed(42)  # Fix seed for reproduceability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data.\n",
    "mineral_dataset_path = os.path.join(\n",
    "    DATA_DIR, \"extracted_mineral_pixel_data\", \"mineral_pixel_dataset.json\"\n",
    ")\n",
    "bland_dataset_path = os.path.join(\n",
    "    DATA_DIR, \"extracted_bland_pixel_data\", \"bland_pixel_dataset.json\"\n",
    ")\n",
    "mineral_dataset = preprocessing.load_dataset(mineral_dataset_path)\n",
    "bland_dataset = preprocessing.load_dataset(bland_dataset_path)\n",
    "\n",
    "# Get as many bland pixels from the bland pixel set as desired.\n",
    "# Sample equally from each image of bland pixels.\n",
    "num_bland_images = bland_dataset[\"Image_Name\"].nunique()\n",
    "samples_per_image = NUM_BLAND_PIXELS // num_bland_images\n",
    "bland_dataset_sample = (\n",
    "    bland_dataset.groupby(\"Image_Name\")\n",
    "    .apply(lambda x: x.sample(min(len(x), samples_per_image), random_state=42))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Combine the bland and mineral datasets, then apply all preprocessing steps.\n",
    "dataset = pd.concat(\n",
    "    [mineral_dataset, bland_dataset_sample], ignore_index=True\n",
    ").reset_index(drop=True)\n",
    "dataset = preprocessing.expand_dataset(dataset)\n",
    "dataset = preprocessing.drop_bad_bands(dataset, bands_to_keep=PLEBANI_WAVELENGTHS)\n",
    "dataset = preprocessing.impute_bad_values(dataset, threshold=1)\n",
    "dataset = preprocessing.impute_atmospheric_artefacts(\n",
    "    dataset, wavelengths=PLEBANI_WAVELENGTHS\n",
    ")\n",
    "noise_dataset = preprocessing.generate_noisy_pixels(dataset.iloc[:, 3:], random_seed=42)\n",
    "input_target_dataset = pd.concat([dataset, noise_dataset], axis=1)\n",
    "train_set, test_set = preprocessing.train_test_split(\n",
    "    input_target_dataset, bland_pixels=True\n",
    ")\n",
    "train_set, validation_set = preprocessing.train_validation_split(\n",
    "    train_set, bland_pixels=True\n",
    ")\n",
    "\n",
    "# Split the training, validation, and testing sets.\n",
    "X_train, y_train, ancillary_train = preprocessing.split_features_targets_anciliary(\n",
    "    train_set\n",
    ")\n",
    "X_test, y_test, ancillary_test = preprocessing.split_features_targets_anciliary(\n",
    "    test_set\n",
    ")\n",
    "X_validation, y_validation, ancillary_validation = (\n",
    "    preprocessing.split_features_targets_anciliary(validation_set)\n",
    ")\n",
    "\n",
    "# Fit a scaler to the training data, and then apply it to the validation and test data.\n",
    "X_train, feature_scaler = preprocessing.standardise(X_train, method=\"RobustScaler\")\n",
    "X_test, _ = preprocessing.standardise(\n",
    "    X_test, method=\"RobustScaler\", scaler=feature_scaler\n",
    ")\n",
    "X_validation, _ = preprocessing.standardise(\n",
    "    X_validation, method=\"RobustScaler\", scaler=feature_scaler\n",
    ")\n",
    "\n",
    "X_test_tensor = torch.from_numpy(X_test.values).float()\n",
    "y_test_tensor = torch.from_numpy(y_test.values).float()\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(\n",
    "    os.path.join(PACKAGE_DIR, \"n2n4m\", \"data\", \"trained_model_weights.pt\"),\n",
    "    map_location=torch.device(\"cpu\"),\n",
    ")\n",
    "# If the model was trained on multiple GPUs, the keys will have \"module.\" in them. As we are running inference only on CPU, we need to remove this.\n",
    "if \"module.\" in list(state_dict.keys())[0]:\n",
    "    state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "model = Noise2Noise1D(kernel_size=5, depth=3, num_blocks=4, num_input_features=350)\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "N2N4M_test_set_predictions = predict(model, test_loader, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for N2N4M on test set: 4.664849076300921e-06\n"
     ]
    }
   ],
   "source": [
    "loss_func = nn.MSELoss()\n",
    "N2NHD_test_loss = loss_func(\n",
    "    N2N4M_test_set_predictions, torch.from_numpy(y_test.values)\n",
    ").item()\n",
    "print(f\"MSE for N2N4M on test set: {N2NHD_test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CoTCAT performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_unstandardised = feature_scaler.inverse_transform(\n",
    "    X_test\n",
    ")  # Back to the original scale\n",
    "X_test_unstandardised = X_test_unstandardised.reshape(\n",
    "    21, -1, len(PLEBANI_WAVELENGTHS)\n",
    ")  # Reshape to be 3D for the cotcat_denoise function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cotcat_test_set_predictions = cotcat_denoise(\n",
    "    X_test_unstandardised, wavelengths=PLEBANI_WAVELENGTHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for cotcat on test set: 4.951200574360762e-06\n"
     ]
    }
   ],
   "source": [
    "cotcat_test_set_predictions = cotcat_test_set_predictions.reshape(\n",
    "    -1, 350\n",
    ")  # Reshape to be 2D for the loss function\n",
    "cotcat_test_loss = loss_func(\n",
    "    torch.from_numpy(cotcat_test_set_predictions), torch.from_numpy(y_test.values)\n",
    ").item()\n",
    "print(f\"MSE for cotcat on test set: {cotcat_test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CRISM_env_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
